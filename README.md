# ğŸš€ Kafka Consumer/Producer com Docker

Este projeto demonstra como configurar e usar Apache Kafka com Docker Compose, incluindo exemplos de Consumer e Producer em Python.

## ğŸ“‹ SumÃ¡rio

- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Docker Compose](#-docker-compose)
- [Makefile](#-makefile)
- [InstalaÃ§Ã£o e Setup](#-instalaÃ§Ã£o-e-setup)
- [Como Usar](#-como-usar)
- [Exemplos PrÃ¡ticos](#-exemplos-prÃ¡ticos)
- [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)

## ğŸ›  PrÃ©-requisitos

- Docker e Docker Compose instalados
- Python 3.7+
- Make (opcional, mas recomendado)

## ğŸ“ Estrutura do Projeto

```
kafka-project/
â”œâ”€â”€ docker-compose.yml     # ConfiguraÃ§Ã£o do Kafka
â”œâ”€â”€ Makefile              # Comandos automatizados
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â”œâ”€â”€ README.md            # Este arquivo
â””â”€â”€ src/
    â”œâ”€â”€ simple_consumer.py
    â””â”€â”€ simple_producer.py
```

## ğŸ³ Docker Compose

O arquivo `docker-compose.yml` configura um ambiente Kafka completo com:

### ServiÃ§os IncluÃ­dos

#### ğŸ”§ Zookeeper
- **Porta**: 2181
- **FunÃ§Ã£o**: CoordenaÃ§Ã£o e configuraÃ§Ã£o do cluster Kafka
- **Volumes**: Dados persistentes em `zookeeper-data` e `zookeeper-logs`

#### ğŸ“¨ Kafka Broker
- **Porta Externa**: 9092 (para aplicaÃ§Ãµes externas)
- **Porta Interna**: 29092 (para comunicaÃ§Ã£o entre containers)
- **Porta JMX**: 9101 (para monitoramento)
- **Volumes**: Dados persistentes em `kafka-data`

#### ğŸ–¥ Kafka UI
- **Porta**: 8080
- **URL**: http://localhost:8080
- **FunÃ§Ã£o**: Interface web para gerenciar tÃ³picos, visualizar mensagens e monitorar o cluster

### ConfiguraÃ§Ãµes Importantes

```yaml
# ConfiguraÃ§Ã£o para desenvolvimento local
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092

# CriaÃ§Ã£o automÃ¡tica de tÃ³picos
KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

# ConfiguraÃ§Ãµes para ambiente de desenvolvimento (single-broker)
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```

## ğŸ”¨ Makefile

O Makefile automatiza tarefas comuns e inclui as seguintes funcionalidades:

### VariÃ¡veis de ConfiguraÃ§Ã£o

```makefile
PYTHON := python3              # Comando Python
PIP := pip3                   # Comando pip
DOCKER_COMPOSE := docker-compose  # Docker Compose
KAFKA_FILE := simple_kafka.py     # Arquivo principal (nÃ£o usado nesta versÃ£o)
```

### Sistema de Cores

O Makefile inclui um sistema de cores para melhor visualizaÃ§Ã£o:
- ğŸŸ¢ **Verde**: Sucessos e confirmaÃ§Ãµes
- ğŸŸ¡ **Amarelo**: Avisos e processos em andamento
- ğŸ”´ **Vermelho**: Erros
- ğŸ”µ **Azul**: InformaÃ§Ãµes importantes

### Comandos Principais

#### ğŸ“¦ Gerenciamento de DependÃªncias
```bash
make install    # Instala dependÃªncias do requirements.txt
```

#### ğŸ³ Gerenciamento do Kafka
```bash
make kafka-up   # Inicia o ambiente Kafka
make kafka-down # Para o ambiente Kafka
```

#### ğŸš€ ExecuÃ§Ã£o de AplicaÃ§Ãµes
```bash
make consumer   # Executa ./src/simple_consumer.py
make producer   # Executa ./src/simple_producer.py
```

## ğŸš€ InstalaÃ§Ã£o e Setup

### 1. Clone o Projeto
```bash
git clone <seu-repositorio>
cd kafka-project
```

### 2. Crie o arquivo requirements.txt
```bash
echo "kafka-python==2.0.2" > requirements.txt
```

### 3. Setup Completo
```bash
# Instalar dependÃªncias Python
make install

# Subir ambiente Kafka
make kafka-up
```

### 4. Verificar InstalaÃ§Ã£o
- Kafka UI: http://localhost:8080
- Verifique se os containers estÃ£o rodando:
```bash
docker-compose ps
```

## ğŸ¯ Como Usar

### MÃ©todo 1: Usando Makefile (Recomendado)

```bash
# Terminal 1 - Iniciar Consumer
make consumer

# Terminal 2 - Executar Producer
make producer
```

### MÃ©todo 2: Comandos Diretos

```bash
# Subir Kafka
docker-compose up -d

# Terminal 1 - Consumer
python3 ./src/simple_consumer.py

# Terminal 2 - Producer  
python3 ./src/simple_producer.py
```

## ğŸ’¡ Exemplos PrÃ¡ticos

### 1. Teste BÃ¡sico Producer/Consumer

```bash
# 1. Subir ambiente
make kafka-up

# 2. Terminal 1: Consumer
make consumer

# 3. Terminal 2: Producer
make producer
```

### 2. Monitoramento via Kafka UI

1. Acesse: http://localhost:8080
2. Navegue atÃ© "Topics"
3. Veja as mensagens em tempo real
4. Monitore partiÃ§Ãµes e offsets

### 3. Consumer Personalizado

Crie seu prÃ³prio consumer em `src/simple_consumer.py`:

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'meu-topico',
    bootstrap_servers=['localhost:9092'],
    group_id='meu-grupo',
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest'
)

print("ğŸ‘‚ Aguardando mensagens...")

for message in consumer:
    print(f"ğŸ“¨ Recebido: {message.value}")
    # Processe sua mensagem aqui
```

### 4. Producer Personalizado

Crie seu prÃ³prio producer em `src/simple_producer.py`:

```python
from kafka import KafkaProducer
import json
import time

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

for i in range(10):
    message = {
        'id': i,
        'data': f'Mensagem {i}',
        'timestamp': time.time()
    }
    
    producer.send('meu-topico', message)
    print(f"âœ… Enviado: {message}")
    time.sleep(1)

producer.close()
```

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### ConexÃ£o do Kafka

Para aplicaÃ§Ãµes **dentro do Docker**:
```python
bootstrap_servers=['kafka:29092']
```

Para aplicaÃ§Ãµes **no host local**:
```python
bootstrap_servers=['localhost:9092']
```

### Consumer Groups

```python
# MÃºltiplos consumers no mesmo grupo = load balancing
consumer = KafkaConsumer(
    'meu-topico',
    group_id='processamento-grupo',  # Mesmo grupo
    bootstrap_servers=['localhost:9092']
)
```

### MÃºltiplos TÃ³picos

```python
# Subscribe em vÃ¡rios tÃ³picos
consumer = KafkaConsumer(
    bootstrap_servers=['localhost:9092'],
    group_id='multi-grupo'
)
consumer.subscribe(['topico-1', 'topico-2', 'topico-3'])
```

## ğŸ›  SoluÃ§Ã£o de Problemas

### Kafka nÃ£o conecta

```bash
# Verificar containers
docker-compose ps

# Ver logs
docker-compose logs kafka

# Reiniciar ambiente
make kafka-down
make kafka-up
```

### Erro de dependÃªncias

```bash
# Reinstalar dependÃªncias
pip3 install kafka-python==2.0.2

# Ou usar o Makefile
make install
```

### Consumer nÃ£o recebe mensagens

1. Verificar se o tÃ³pico existe no Kafka UI
2. Confirmar `group_id` diferente se quiser reprocessar
3. Usar `auto_offset_reset='earliest'` para ler desde o inÃ­cio

### Porta jÃ¡ em uso

```bash
# Verificar o que estÃ¡ usando a porta
lsof -i :9092

# Parar todos os containers
docker-compose down

# Limpar completamente
docker-compose down -v --remove-orphans
```

## ğŸ“Š Monitoramento

### Kafka UI (Recomendado)
- URL: http://localhost:8080
- Funcionalidades:
  - Visualizar tÃ³picos e mensagens
  - Monitorar consumer groups
  - Verificar partiÃ§Ãµes e offsets

### Comandos Docker

```bash
# Status dos containers
docker-compose ps

# Logs em tempo real
docker-compose logs -f kafka

# Uso de recursos
docker stats
```

## ğŸ“ Notas Importantes

- Este setup Ã© para **desenvolvimento local**
- Para **produÃ§Ã£o**, configure mÃºltiplos brokers e replicaÃ§Ã£o
- Sempre monitore o uso de disco dos volumes
- Use `consumer groups` para escalabilidade
- Implemente tratamento de erros robusto



